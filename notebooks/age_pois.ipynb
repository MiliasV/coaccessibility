{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting, Preprocessing & Storing CBS NL Population Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import swifter\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import db_connection_string\n",
    "from sqlalchemy import create_engine\n",
    "from descartes import PolygonPatch\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "# ox.config(log_console=True, use_cache=True)\n",
    "# ox.__version__\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# db initialization\n",
    "# store to db\n",
    "db_connection_string = 'postgresql://postgres:postgres@localhost/age_segregation'\n",
    "engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import geopandas as gpd\n",
    "\n",
    "# read file\n",
    "gdf = gpd.read_file(\"data/2021-cbs_vk100_2020_v1/CBS_vk100_2020_v1.shp\")\n",
    "# values -9997 represent 0 OR values smaller than \"4\". We treat them as 0.\n",
    "gdf = gdf.replace(-99997, 0)\n",
    "# compute percentages of each age\n",
    "for age in ['014','1524', '2544', '4564','65PL']:\n",
    "    gdf[\"INW_\" + age +\"_PERC\"] = gdf[\"INW_\" + age]/(gdf[\"INW_014\"] + gdf[\"INW_1524\"] + gdf[\"INW_2544\"]+ gdf[\"INW_4564\"]+df[\"INW_65PL\"])\n",
    "# compute most dominant age\n",
    "gdf[\"MAX_AGE_PERC\"] = gdf[['INW_014_PERC','INW_1524_PERC','INW_2544_PERC','INW_4564_PERC','INW_65PL_PERC']].idxmax(axis=1)\n",
    "\n",
    "# gdf.to_postgis(\"nl_population_2020_100\", con=engine, schema='netherlands')\n",
    "gdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping to contain only one NL City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import swifter\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import geopandas\n",
    "from sqlalchemy import create_engine\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "\n",
    "# based on a city name clip NL data and store city-population in a separate schema in db\n",
    "def store_pop_of_a_city_nl(gdf, city_name, table_name, schema, engine):\n",
    "    # get nl data from db\n",
    "    db_connection_string = 'postgresql://postgres:postgres@localhost/age_segregation'\n",
    "    engine = create_engine(db_connection_string)\n",
    "    sql = 'SELECT * from netherlands.nl_population_2020_100'\n",
    "    gdf = gpd.GeoDataFrame.from_postgis(sql, engine, geom_col='geometry')\n",
    "    # clip data according to city\n",
    "    place = ox.geocode_to_gdf(city_name)\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    utm = pyproj.CRS('EPSG:28992')\n",
    "    project = pyproj.Transformer.from_crs(wgs84,utm, always_xy=True).transform\n",
    "    city_mask = transform(project, place.geometry[0])\n",
    "    gdf_city = geopandas.clip(gdf, city_mask)\n",
    "    #store city data to db\n",
    "    gdf_city.to_postgis(table_name, con=engine, schema=schema)\n",
    "    \n",
    "# store_pop_of_a_city_nl(gdf, 'Amsterdam', 'ams_population_2020_100', schema='amsterdam', engine=engine)\n",
    "# store_pop_of_a_city_nl(gdf, 'Rotterdam', 'rot_population_2020_100', schema='rotterdam', engine=engine)\n",
    "# store_pop_of_a_city_nl(gdf, 'Hague', 'hag_population_2020_100', schema='hague', engine=engine)\n",
    "# store_pop_of_a_city_nl(gdf, 'Utrecht', 'utr_population_2020_100', schema='utrecht', engine=engine)\n",
    "# store_pop_of_a_city_nl(gdf, 'Eindhoven', 'ein_population_2020_100', schema='einhoven', engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating isochrones based on walking speed and street network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descartes import PolygonPatch\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "# ox.config(log_console=True, use_cache=True)\n",
    "# ox.__version__\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_iso_polys(G, G_wgs84, point, trip_times,edge_buff=25, node_buff=50, infill=False):\n",
    "    source_node = ox.distance.nearest_nodes(G_wgs84, point.x, point.y)\n",
    "    isochrone_polys = []\n",
    "    for trip_time in sorted(trip_times, reverse=True):\n",
    "        subgraph = nx.ego_graph(G, source_node, radius=trip_time, distance='time')\n",
    "        node_points = [Point((data['x'], data['y'])) for node, data in subgraph.nodes(data=True)]\n",
    "        nodes_gdf = gpd.GeoDataFrame({'id': subgraph.nodes()}, geometry=node_points)\n",
    "        nodes_gdf = nodes_gdf.set_index('id')\n",
    "        edge_lines = []\n",
    "        for n_fr, n_to in subgraph.edges():\n",
    "            f = nodes_gdf.loc[n_fr].geometry\n",
    "            t = nodes_gdf.loc[n_to].geometry\n",
    "            edge_lookup = G.get_edge_data(n_fr, n_to)[0].get('geometry',  LineString([f,t]))\n",
    "            edge_lines.append(edge_lookup)\n",
    "\n",
    "        n = nodes_gdf.buffer(node_buff).geometry\n",
    "        e = gpd.GeoSeries(edge_lines).buffer(edge_buff).geometry\n",
    "        all_gs = list(n) + list(e)\n",
    "        new_iso = gpd.GeoSeries(all_gs).unary_union\n",
    "        # try to fill in surrounded areas so shapes will appear solid and blocks without white space inside them\n",
    "        if infill:\n",
    "            try:\n",
    "                new_iso = Polygon(new_iso.exterior)\n",
    "            except:\n",
    "                return None       \n",
    "    isochrone_polys.append(new_iso)\n",
    "    return isochrone_polys[0]\n",
    "\n",
    "def make_iso_polys_for_viz(G, G_wgs84, point, trip_times,edge_buff=25, node_buff=50, infill=False):\n",
    "    source_node = ox.distance.nearest_nodes(G_wgs84, point.x, point.y)\n",
    "    isochrone_polys = []\n",
    "    for trip_time in sorted(trip_times, reverse=True):\n",
    "        subgraph = nx.ego_graph(G, source_node, radius=trip_time, distance='time')\n",
    "        node_points = [Point((data['x'], data['y'])) for node, data in subgraph.nodes(data=True)]\n",
    "        nodes_gdf = gpd.GeoDataFrame({'id': subgraph.nodes()}, geometry=node_points)\n",
    "        nodes_gdf = nodes_gdf.set_index('id')\n",
    "\n",
    "        edge_lines = []\n",
    "        for n_fr, n_to in subgraph.edges():\n",
    "            f = nodes_gdf.loc[n_fr].geometry\n",
    "            t = nodes_gdf.loc[n_to].geometry\n",
    "            edge_lookup = G.get_edge_data(n_fr, n_to)[0].get('geometry',  LineString([f,t]))\n",
    "            edge_lines.append(edge_lookup)\n",
    "\n",
    "        n = nodes_gdf.buffer(node_buff).geometry\n",
    "        e = gpd.GeoSeries(edge_lines).buffer(edge_buff).geometry\n",
    "        all_gs = list(n) + list(e)\n",
    "        new_iso = gpd.GeoSeries(all_gs).unary_union\n",
    "        # try to fill in surrounded areas so shapes will appear solid and blocks without white space inside them\n",
    "        if infill:\n",
    "            new_iso = Polygon(new_iso.exterior)\n",
    "        isochrone_polys.append(new_iso)\n",
    "    return isochrone_polys\n",
    "\n",
    "def add_iso_polys_to_viz(G, G_wgs84, point_list, trip_times, ax):\n",
    "    for x in point_list: \n",
    "        isochrone_polys = make_iso_polys_for_viz(G, G_wgs84, x, trip_times, edge_buff=25, node_buff=0, infill=True)\n",
    "        for polygon, fc in zip(isochrone_polys, iso_colors):\n",
    "            patch = PolygonPatch(polygon, fc=fc, ec='none', alpha=0.6, zorder=-1)\n",
    "            ax.add_patch(patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute isochrones per walking speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calculating speeds. Generating Polygons....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c914ae62033e4b248111f58134d6a753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE )--> iso_15_avg_speed_75.6\n",
      "Time needed --- 8924.46990609169 seconds ---\n",
      "Done calculating speeds. Generating Polygons....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17753f70de8b4a8eb77c17c8298c7a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyproj\n",
    "import swifter\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "# \"eindhoven\", hague\n",
    "cities = [\"utrecht\",  \"rotterdam\", \"amsterdam\"]\n",
    "for city in cities:\n",
    "    # download the street network\n",
    "    G_wgs84 = ox.graph_from_place(city,retain_all=True, network_type='walk')\n",
    "    #remove isolated nodes\n",
    "    G_wgs84.remove_nodes_from(list(nx.isolates(G_wgs84)))\n",
    "    # netherlands projection\n",
    "    G = ox.project_graph(G_wgs84, to_crs='epsg:28992')\n",
    "    \n",
    "    sql = \"Select * from \" + city + \".\" + city[0:3] + \"_population_2020_100\"\n",
    "    # population data\n",
    "    gdf_pop = gpd.GeoDataFrame.from_postgis(sql, engine, geom_col='geometry')\n",
    "\n",
    "    # tranform from utm to wgs84\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    utm = pyproj.CRS('EPSG:28992')\n",
    "    project = pyproj.Transformer.from_crs(utm, wgs84, always_xy=True).transform\n",
    "\n",
    "    # create centroids and project them to wgs84\n",
    "    gdf_pop[\"centroid_wgs84\"] = gdf_pop.apply(lambda row: transform(project, row[\"geometry\"].centroid), axis=1)\n",
    "\n",
    "    # speed in meters per minute\n",
    "    walking_speed = {'avg_speed': 75.6}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    trip_time = 15\n",
    "    # for trip_time in trip_times:\n",
    "    # add an edge attribute for time in minutes required to traverse each edge\n",
    "    for age in walking_speed:\n",
    "        for u, v, k, data in G.edges(data=True, keys=True):\n",
    "            data['time'] = data['length'] / walking_speed[age]\n",
    "        walking_speed_col_name = str(walking_speed[age]).replace(\".\",\"_\")\n",
    "        print(\"Done calculating speeds. Generating Polygons....\")\n",
    "        gdf_pop[\"iso_\" + str(trip_time) +\"_\" + age + \"_\" + walking_speed_col_name] = gdf_pop.swifter.apply(lambda row: make_iso_polys(G, G_wgs84, row.centroid_wgs84, [trip_time], edge_buff=25, node_buff=0, infill=True), axis=1)\n",
    "        print(\"DONE )--> iso_\" + str(trip_time) +\"_\" + age + \"_\" + str(walking_speed[age]))\n",
    "        print(\"Time needed --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    gdf_pop.to_postgis(city[0:3] + \"_population_iso_2020_100\", con=engine, schema=city)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from shapely import wkt\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geoalchemy2.shape import to_shape \n",
    "from pyproj import Proj, transform\n",
    "\n",
    "\n",
    "db_connection_string = 'postgresql://postgres:postgres@145.100.57.202/age_accessibility_study'\n",
    "\n",
    "# db_connection_string = 'postgresql://postgres:postgres@127.0.0.1/case_study_i'\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# df.to_postgis(\"netherlands_population_2020_100\", engine)\n",
    "# gdf_pop = gpd.GeoDataFrame.from_postgis(\"fsq_ams_whole_40_msc_typel1\", engine, geom_col='geom')\n",
    "df = pd.read_sql(\"fsq_ams_whole_40_msc_typel1\", engine)\n",
    "\n",
    "df[\"geom\"] = df.apply(lambda row: to_shape(row.geom), axis=1)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geom\", crs='epsg:4326')\n",
    "\n",
    "ymax = 488346.86199703\n",
    "ymin = 485438.26505735\n",
    "xmax = 122484.72033747\n",
    "xmin = 119584.38934079\n",
    "\n",
    "xmax,ymax = transform('epsg:28992','epsg:4326',xmax,ymax)\n",
    "xmin,ymin = transform('epsg:28992','epsg:4326',xmin,ymin)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gdf_center = gdf.cx[ymin:ymax, xmin:xmax]\n",
    "\n",
    "# df['geometry'] = df.geom.apply(wkt.loads)\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=\"geom\", crs='epsg:4326')\n",
    "gdf_center.to_postgis(\"fsq_ams_center_40_msc_typel1\", engine)\n",
    "\n",
    "# gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin\n",
    "gdf_center = gdf.cx[4.739844:5.068583, 52.27876211:52.4305255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from shapely import wkt\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geoalchemy2.shape import to_shape \n",
    "from pyproj import Proj, transform\n",
    "\n",
    "\n",
    "db_connection_string = 'postgresql://postgres:postgres@localhost/case_study_i'\n",
    "\n",
    "# db_connection_string = 'postgresql://postgres:postgres@127.0.0.1/case_study_i'\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# df.to_postgis(\"netherlands_population_2020_100\", engine)\n",
    "# gdf_park = gpd.GeoDataFrame.from_postgis(\"park_ams_diversity\", engine, geom_col='park_geom')\n",
    "# df = pd.read_sql(\"pop_ams_all\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsq = pd.read_sql_query('select * from \"fsq_ams_diversity\"',con=engine)\n",
    "df_fsq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsq = df_fsq.sort_values('total_pop')\n",
    "df_fsq.plot(x = 'total_pop', y='age_entropy_index',grid=True, loglog=True, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsq_pop_per_type = pd.read_sql_query('select * from \"fsq_pop_per_typel1\"',con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_fsq_pop_per_type.plot.bar(x='fsq_typel1', y='perc_014', rot=30, figsize=(15,10))\n",
    "# ax = df_fsq_pop_per_type.plot.bar(x='fsq_typel1', y='perc_1524', rot=30, figsize=(15,10))\n",
    "# ax = df_fsq_pop_per_type.plot.bar(x='fsq_typel1', y='perc_2544', rot=30, figsize=(15,10))\n",
    "# ax = df_fsq_pop_per_type.plot.bar(x='fsq_typel1', y='perc_4564', rot=30, figsize=(15,10))\n",
    "# ax = df_fsq_pop_per_type.plot.bar(x='fsq_typel1', y='perc_65pl', rot=30, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsq = pd.read_sql_query('select * from \"fsq_ams_nearby_300_count_info\"',con=engine)\n",
    "df_fsq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsq = df_fsq.sort_values('within_300')\n",
    "df_fsq.plot(x = 'within_300', y='age_entropy_index',grid=True, loglog=True, legend=True, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_park = df_park.sort_values('park_area')\n",
    "\n",
    "df_park.plot(x = 'park_area', y='total_pop',loglog=True, legend=True)\n",
    "df_park.plot(x = 'park_area', y=['age_entropy_index'],loglog=True, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
